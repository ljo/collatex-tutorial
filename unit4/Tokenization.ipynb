{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization, or \"Tokenize Your Own\"\n",
    "\n",
    "Why tokenize your own texts?\n",
    "\n",
    "By default CollateX \"splits on whitespace and interpunction\". This often means that you will get words to be your unit of collation.\n",
    "\n",
    "But what about \"can't\", \"A'dam\", \"Peter's\"?\n",
    "\n",
    "Tokenization defines your *unit of comparison* and thus gives you more control over the comparison.\n",
    "\n",
    "Unfortunately this means learning how to offer a *pretokenized data structure* to CollateX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretokenize text as JSON\n",
    "\n",
    "Assert:\n",
    "\n",
    "    witness_A = \"Peter's cat\"\n",
    "    witness_B = \"Peter's dog\"\n",
    "\n",
    "Problem: \"Peter's cat\" will be tokenized as \"Peter\", \"'\", \"s\" , \"cat\"\n",
    "\n",
    "We will use JSON to tell CollateX to 'read' and collate it differently\n",
    "\n",
    "JSON data is a mixture of arrays (lists) and objects (where a *key* is associated with a *value*):\n",
    "\n",
    "Arrays look like this: \n",
    "\n",
    "    [ \"i\", \"am\", \"the\", \"words\", \"in\", \"an\", \"array\" ]\n",
    "\n",
    "Objects look like this:\n",
    "\n",
    "    { \"a_variable_name\": \"My first value\", \"another_varible\": \"Another thingy\" }\n",
    "    \n",
    "In JSON you may combine this:\n",
    "\n",
    "    { \"a_witness_object\": { \"siglum\": \"A\", \"tokens\": [] } } \n",
    "    \n",
    "Or the same, laid out so that it is somewhat easier to read:\n",
    "\n",
    "    { \"a_witness_object\":\n",
    "        { \n",
    "            \"siglum\": \"A\",\n",
    "            \"tokens\": []\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try the good old fashioned way…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collatex import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collation = Collation()\n",
    "collation.add_plain_witness( \"A\", \"Peter's cat\")\n",
    "collation.add_plain_witness( \"B\", \"Peter's dog\" )\n",
    "alignment_table = collate( collation, layout='vertical', segmentation=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|   A   |   B   |\n",
      "+-------+-------+\n",
      "| Peter | Peter |\n",
      "+-------+-------+\n",
      "|   '   |   '   |\n",
      "+-------+-------+\n",
      "|   s   |   s   |\n",
      "+-------+-------+\n",
      "|  cat  |  dog  |\n",
      "+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "print( alignment_table )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hmm.. indeed not quite what we want, thus…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_a = [ { \"t\": \"Peter's\" }, { \"t\": \"cat\" } ]\n",
    "tokens_b = [ { \"t\": \"Peter's\" }, { \"t\": \"dog\" } ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "witness_a = { \"id\": \"A\", \"tokens\": tokens_a }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'A', 'tokens': [{'t': \"Peter's\"}, {'t': 'cat'}]}\n"
     ]
    }
   ],
   "source": [
    "print( witness_a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "witness_b = { \"id\": \"B\", \"tokens\": tokens_b }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JSON_input = { \"witnesses\": [ witness_a, witness_b ] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = collate_pretokenized_json( JSON_input, output='table' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+\n",
      "| A | Peter's | cat |\n",
      "| B | Peter's | dog |\n",
      "+---+---------+-----+\n"
     ]
    }
   ],
   "source": [
    "print( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
